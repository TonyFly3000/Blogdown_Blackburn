<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data on Tony Duan</title>
    <link>/tags/data/</link>
    <description>Recent content in Data on Tony Duan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018. All rights reserved.</copyright>
    <lastBuildDate>Sat, 19 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/data/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A/B testing with Google Analytics meetup</title>
      <link>/post/a-b-testing-with-google-analytics-meetup/</link>
      <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/a-b-testing-with-google-analytics-meetup/</guid>
      <description>A/B testing with Google Analytics and OptimiseHost by 55 analytic and Aftership@Techtemple.meetup:http://www.huodongxing.com/event/8474882293500
Summary:
Company should provide tailor made content to increase customer satisfaction,engagement and ROI
data value: opportunity-&amp;gt; data-&amp;gt; informaction-&amp;gt; solution-&amp;gt; decision
Google Analytics and Optimise can easily set up A/B testing:Set up KPI with Google AnalyticsSet up A/B testing with Google Optimisepaste code into your websiteget report from Google Optimiseco work space : Tech temple</description>
    </item>
    
    <item>
      <title>Pydata HK meetup</title>
      <link>/post/pydata-hk-meetup/</link>
      <pubDate>Thu, 20 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/pydata-hk-meetup/</guid>
      <description>My first Pydata meetup @The Hong Kong Polytechnic University:Event:https://www.meetup.com/PyData-Hong-Kong/events/254406736/
Discovering Frequent Patterns in Time Series through Unsupervised Data Mining Techniques: the Case of the Energy Profiling in Buildings by Engineer Marco Savino Piscitelli
Write Better Python Code by Mr. Anthony Chiu
</description>
    </item>
    
    <item>
      <title>【數字‧你懂的】從蘋果iPhone看美中貿易逆差</title>
      <link>/post/data-you-know-iphone/</link>
      <pubDate>Tue, 04 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/data-you-know-iphone/</guid>
      <description>Please advise to remove immediately if any infringement caused
Apple become the first US company with market cap &amp;gt;1T USD after a strong 2018Q3 earning when stock price go up to $200 per sharePetroChina is the first company market cap &amp;gt;1T USD at 2007 but it decrease to 200B until todayChina export 61M iphones worth $15B to US in 2017 which contribute 5% of total US-China trade deficit $375B$1000 iphoneX manufacture cost is $350 and 5% of it contribute by China ,mainly battery and assemblyReferencehttps://www.</description>
    </item>
    
    <item>
      <title>Decision Tree model in python</title>
      <link>/post/decision-tree-model-in-python/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/decision-tree-model-in-python/</guid>
      <description>import pacakges and load iris dataset
from sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitfrom sklearn import treefrom sklearn.metrics import accuracy_scoreiris = load_iris()print (iris.feature_names) # metadata: names of the features## [&amp;#39;sepal length (cm)&amp;#39;, &amp;#39;sepal width (cm)&amp;#39;, &amp;#39;petal length (cm)&amp;#39;, &amp;#39;petal width (cm)&amp;#39;]print (iris.target_names) # metadata: names of the different types of flowers## [&amp;#39;setosa&amp;#39; &amp;#39;versicolor&amp;#39; &amp;#39;virginica&amp;#39;]X = iris.data # featuresy = iris.target # labelsX_train is train features and X_test is test features</description>
    </item>
    
    <item>
      <title>KNN model in python</title>
      <link>/post/knn-model-in-python/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/knn-model-in-python/</guid>
      <description>1.Get:import pacakges and load iris dataset
from sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.metrics import accuracy_scoreiris = load_iris()2.CleanX_train is train features and X_test is test features.y_train is train label and y_test is test label.with 0.3 splict, we have 70% obs(105) for training and 30% obs(45) for testing.
print (iris.feature_names) # metadata: names of the features## [&amp;#39;sepal length (cm)&amp;#39;, &amp;#39;sepal width (cm)&amp;#39;, &amp;#39;petal length (cm)&amp;#39;, &amp;#39;petal width (cm)&amp;#39;]print (iris.</description>
    </item>
    
    <item>
      <title>Machine Learning over Coffee with Josh Gordon</title>
      <link>/post/machine-learning-over-coffee-with-josh-gordon/</link>
      <pubDate>Thu, 02 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/machine-learning-over-coffee-with-josh-gordon/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>