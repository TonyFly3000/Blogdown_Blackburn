---
title: Tensorflow in Python系列(1) :数字图片分类 MNIST image classification
author: ''
date: '2018-07-30'
slug: tensorflow-in-python-1-mnist-image-classification
categories: []
tags: []
description: 'Tensorflow in Python系列(1) :数字图片分类 MNIST image'
topics: []
---


## 开篇
- Tensorflow in Python 系列，将分享如何使用Python语言在Tensorflow/Keras 框架中训练深度学习模型。
- MNIST 全称为 Modified National Institute of Standards and Technology。这个名词一点也不重要。
- MNIST 数据为 7万张（6万张训练+1万张测试） 0-9的手写数字图片

## 安装 Python 和 Anaconda 

此次省略300字。建议使用云计算平台。如Kaggle Kernel/Google Codelab/Google Cloud 等

可参考【在 Google Cloud 安装 jupyter notebook】： https://tduan.netlify.com/post/google-cloud-jupyter-notebook/



## 安装  tensorflow/keras package

如果你的计算环境有GPU,可以安装GPU版本(tensorflow-gpu==2.0.0-beta1)

```{r, eval=FALSE}
!pip install tensorflow==2.0.0-beta1

```

查看 tensorflow 版本。

```{r ,message = FALSE,warning = FALSE,eval=FALSE}
!pip install tensorflow==2.0.0-beta1
import tensorflow as tf
from tensorflow import keras
print(tf.__version__)
```



## 1.导入数据

导入4个数据集，分别为：

- x_train:  6万张训练数字图片
- y_train： 6万个训练数字0-9标签
- x_test：  1万张测试数字图片
- y_test：  1万个测试数字0-9标签

为什么有4个数据集 ?

- 带x的通常为特征(feature)。带y的为标签(label)。
- 训练数据是用来训练模型。测试数据不参加建模，而是模型建立后是用来测试模型的效果。

```{r, message = FALSE,warning = FALSE,eval=FALSE}
# input data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

```


这些图片长这个样

```{r, message = FALSE,warning = FALSE,eval=FALSE}
plt.figure()
plt.imshow(x_train[0])
plt.colorbar()
plt.grid(False)
plt.show()

```



## 2.数据探索

图片原理：

28 × 28=784 的像素(pixel)组成一张图片。而每个彩色的像素是由RBG 3个由0-255 的数字组成。由于这里的像素是黑白的像素，所以一个像素只有1个数字。0-255，数字越大颜色越浅。比如0为黑色，255为白色


```{r, message = FALSE,warning = FALSE,eval=FALSE}
x_train.shape
x_test.shape

y_train.shape
y_test.shape

```

## 3.数据处理


```{r message = FALSE,warning = FALSE,eval=FALSE}
x_train = x_train / 255.0

x_test = x_test/ 255.0
```

## 4.设计模型


### 建立深度神经网络模型(deep neural network)

网络结构介绍。为容易理解, tensor 约等于 neural 约等于 数字。

输入层：每个图片的形状为784型状的数字的输入层

第一层:使用 'relu' 的256个tensor 的隐藏层 (relu 是什么？后续文章再聊)

第二层:使用 'relu' 的128个tensor 的隐藏层

输出层:使用 'softmax' 的 10个  加总为1 的 0到1的概率 的 输出层 (softmax 是什么？后续文章再聊)


```{r ,message = FALSE,warning = FALSE,eval=FALSE}

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(256, activation=tf.nn.relu),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])

```

### 神经网络型图：

![](https://tensorflow.rstudio.com/tensorflow/articles/images/softmax-regression-scalargraph.png){width=80%}

### 神经网络公式：

公式是我们设计模型的时候定义的。比如图中的模型。W11-W33 9个weight 和 b1-b3 3个bias 经过训练得出。所以模型训练的Learnable Parameters=9+3=12


![](https://tensorflow.rstudio.com/tensorflow/articles/images/softmax-regression-vectorequation.png){width=80%}

### 模型的架构:
Learnable Parameters: input*output+bias 

第一层:使用 'relu' 的256个tensor 的隐藏层：
Learnable Parameters:200960=784*256 + 256


第二层:使用 'relu' 的128个tensor 的隐藏层：
Learnable Parameters:32896=256*128+128


输出层:使用 'softmax' 的 10个 0到1的概率 的 输出层:
Learnable Parameters :1290=128*10+10

总Learnable Parameters :235146=200960+32896+1290

```{python message = FALSE,warning = FALSE,eval=FALSE}
model.summary()
```

## 5.compile 模型

```{r, message = FALSE,warning = FALSE,eval=FALSE}
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=["accuracy"]
```



## 6.训练模型 

一堆数据处理转换。模型设计后 。终于可以开始训练模型了。

x_train 为训练数据集特征(6万张照片)。y_train 为训练数据集标签(6万个0-9的标签)

每次读入128张图片。重复训练10次。6万张照片80%用来训练。20%用来验证

结果88%

```{python ,message = FALSE,warning = FALSE,eval=FALSE}
history = model.fit(x_train, y_train,
                    batch_size=64,
                    epochs=10,
                    #validation_split=0.25,
                    validation_data=(x_test, y_test),
                    verbose=1
                    )

# save model

```


```{r, message = FALSE,warning = FALSE,eval=FALSE}
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

```


